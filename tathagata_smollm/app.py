"""
Tathagata (å¦‚æ¥) - SmolLM2-135M Gradio Interface
æ¥µå°AIãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
"""

import gradio as gr
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

print("ğŸŒ Tathagata (å¦‚æ¥) èµ·å‹•ä¸­...")
print("Loading SmolLM2-135M-Instruct...")

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®èª­ã¿è¾¼ã¿
model_name = "HuggingFaceTB/SmolLM2-135M-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    device_map="auto"
)

print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
print(f"ğŸ“Š ãƒ‡ãƒã‚¤ã‚¹: {model.device}")
print(f"ğŸ’¾ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: 135M")

def generate_response(message, history):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
    
    Args:
        message: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        history: ä¼šè©±å±¥æ­´ï¼ˆGradio ChatInterfaceç”¨ï¼‰
    
    Returns:
        str: ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”
    """
    # å…¥åŠ›ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
    inputs = tokenizer(message, return_tensors="pt").to(model.device)
    
    # å¿œç­”ç”Ÿæˆ
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=150,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            pad_token_id=tokenizer.eos_token_id
        )
    
    # ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆå…¥åŠ›éƒ¨åˆ†ã‚’é™¤å¤–ï¼‰
    response = tokenizer.decode(
        outputs[0][inputs.input_ids.shape[1]:],
        skip_special_tokens=True
    )
    
    return response

# Gradio ChatInterface
demo = gr.ChatInterface(
    fn=generate_response,
    title="ğŸŒ Tathagata (å¦‚æ¥) - SmolLM2-135M",
    description="""
    æ¥µå°AIãƒ¢ãƒ‡ãƒ«ï¼ˆ135Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã«ã‚ˆã‚‹ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
    
    **ä½¿ã„æ–¹:**
    - è³ªå•ã‚„å¯¾è©±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„
    - ãƒ¢ãƒ‡ãƒ«ãŒå¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™
    - ä¼šè©±å±¥æ­´ã¯è‡ªå‹•çš„ã«ä¿æŒã•ã‚Œã¾ã™
    
    **ä¾‹:**
    - ã€Œå—ç„¡å¤§æ—¥å¦‚æ¥ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿã€
    - ã€Œçµ±ä¸€æ£˜ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€
    - ã€Œãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã¨ã¯ï¼Ÿã€
    """,
    examples=[
        "å—ç„¡å¤§æ—¥å¦‚æ¥ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "çµ±ä¸€æ£˜ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
        "ãƒªãƒ¼ãƒãƒ³äºˆæƒ³ã¨ã¯ï¼Ÿ",
        "AIã¨ä»æ•™ã®é–¢ä¿‚ã«ã¤ã„ã¦",
    ],
)

if __name__ == "__main__":
    print("\n" + "="*50)
    print("ğŸŒ Tathagata (å¦‚æ¥) æº–å‚™å®Œäº†")
    print("="*50)
    print("\nğŸ“± ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:7860 ã‚’é–‹ã„ã¦ãã ã•ã„")
    print("ğŸŒ å¤–éƒ¨å…¬é–‹URLã‚‚ç”Ÿæˆã•ã‚Œã¾ã™ï¼ˆshare=Trueï¼‰\n")
    
    demo.launch(
        share=True,  # å¤–éƒ¨å…¬é–‹URLç”Ÿæˆ
        server_name="0.0.0.0",  # ã™ã¹ã¦ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ãƒªãƒƒã‚¹ãƒ³
        server_port=7860
    )
